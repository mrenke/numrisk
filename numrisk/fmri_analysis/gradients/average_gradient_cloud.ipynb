{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import datasets\n",
    "import os.path as op\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "bids_folder = '/mnt_03/ds-dnumrisk' \n",
    "subList = [f[4:6] for f in os.listdir(bids_folder) if f[0:4] == 'sub-' and len(f) == 6]\n",
    "\n",
    "# group list\n",
    "df_participants = pd.read_csv(op.join(bids_folder, 'add_tables','subjects_recruit_scan_scanned-final.csv'), header=0) #, index_col=0\n",
    "group_list = df_participants.loc[:,['subject ID','group']].rename(mapper={'subject ID': 'subject'},axis=1).dropna().astype({'subject': int, 'group': int}).set_index('subject')\n",
    "\n",
    "source_folder = op.join(bids_folder,'derivatives','correlation_matrices')\n",
    "target_folder = op.join(bids_folder,'derivatives','gradients')\n",
    "\n",
    "specification = '' # align_spec = '_align-procrustes' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_basic_mask\n",
    "\n",
    "mask, labeling_noParcel = get_basic_mask()\n",
    "N_vertices = len(np.where(mask==True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average correlation matrix for all subs\n",
    "group = 'All'\n",
    "\n",
    "matrix_zeros = np.zeros((N_vertices, N_vertices))\n",
    "av_cm = matrix_zeros.copy()\n",
    "\n",
    "for sub in subList:\n",
    "    try:\n",
    "        correlation_matrix = np.load(op.join(source_folder,f'sub-{sub}_unfiltered{specification}.npy'))\n",
    "        av_cm += np.arctan(correlation_matrix) # fisher-Z-transformed\n",
    "        print(f'subject {sub} added')\n",
    "    except:\n",
    "        print(f'subject {sub} failed')\n",
    "\n",
    "av_cm = av_cm/len(subList)\n",
    "av_cm_transf = np.tan(av_cm) # sanity check: diagonal should be 1 !\n",
    "\n",
    "np.save(op.join(source_folder,f'cm_av_ses1_fsav5_unfiltered.npy'), av_cm_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m av_cm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((N_vertices, N_vertices)) \u001b[38;5;66;03m# matrix with zeros\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m subList_fil:\n\u001b[0;32m----> 8\u001b[0m     correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msub\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_unfiltered\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mspecification\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     av_cm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marctan(correlation_matrix) \u001b[38;5;66;03m# fisher-Z-transformed\u001b[39;00m\n\u001b[1;32m     11\u001b[0m av_cm \u001b[38;5;241m=\u001b[39m av_cm\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(subList)\n",
      "File \u001b[0;32m~/miniconda3/envs/numrefields/lib/python3.10/site-packages/numpy-1.23.4-py3.10-linux-x86_64.egg/numpy/lib/npyio.py:413\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode)\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/miniconda3/envs/numrefields/lib/python3.10/site-packages/numpy-1.23.4-py3.10-linux-x86_64.egg/numpy/lib/format.py:755\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    768\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# groups seperate\n",
    "\n",
    "group = 0\n",
    "subList_fil = [x for x in subList if group_list.loc[int(x)]['group'] == group]\n",
    "\n",
    "av_cm = np.zeros((N_vertices, N_vertices)) # matrix with zeros\n",
    "for sub in subList_fil:\n",
    "    try:\n",
    "        correlation_matrix = np.load(op.join(source_folder,f'sub-{sub}_unfiltered{specification}.npy'))\n",
    "        av_cm += np.arctan(correlation_matrix) # fisher-Z-transformed\n",
    "    except:\n",
    "        print(f'subject {sub} failed')\n",
    "        \n",
    "av_cm = av_cm/len(subList)\n",
    "av_cm_transf = np.tan(av_cm) # sanity check: diagonal should be 1 !\n",
    "\n",
    "np.save(op.join(source_folder,f'cm_av_group-{group}.npy'), av_cm_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now derive GMs from average CMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/numrefields/lib/python3.10/site-packages/brainspace-0.1.4-py3.10.egg/brainspace/gradient/embedding.py:70: UserWarning: Affinity is not symmetric. Making symmetric.\n",
      "  warnings.warn('Affinity is not symmetric. Making symmetric.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sub-avGroupAll: gradients generated\n"
     ]
    }
   ],
   "source": [
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.utils.parcellation import map_to_labels\n",
    "\n",
    "sub = f'avGroup{group}'\n",
    "\n",
    "n_components = 3 # reference gradient only has 3 components anyway... for better alignment one needs more components?! (according to Alam, 2022, L-R GM differences & cognition )\n",
    "\n",
    "target_dir = op.join(bids_folder, 'derivatives', 'gradients', f'sub-{sub}')\n",
    "if not op.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "# load in reference gradient and apply same filter\n",
    "g_ref = np.load(op.join(bids_folder,'derivatives', 'gradients','refGrad-av_task-risk_align-marg.npy')) # same labeling_noParcel as cm_unfiltered\n",
    "#g_ref = g_ref[mask] # not needed here cause \"unfiltered\"\n",
    "\n",
    "# now perform embedding on cleaned data + alignment\n",
    "g_align_fil = GradientMaps(n_components=n_components,alignment='procrustes') # defaults: approacch = 'dm', kernel = None\n",
    "g_align_fil.fit(av_cm_transf,reference=g_ref)\n",
    "print(f'finished sub-{sub}: gradients generated')\n",
    "\n",
    "gm = g_align_fil.gradients_.T # unaligned\n",
    "grad = [None] * n_components\n",
    "for i, g in enumerate(gm): # \n",
    "    grad[i] = map_to_labels(g, labeling_noParcel, mask=mask, fill=np.nan)\n",
    "np.save(op.join(target_dir,f'sub-{sub}_gradients{specification}.npy'), grad) # save all together\n",
    "\n",
    "gm = g_align_fil.aligned_.T # !!!! take .algined_ and not .gradients (which also exists, but those are not aligend)\n",
    "grad = [None] * n_components\n",
    "for i, g in enumerate(gm): # gm.gradients_.T\n",
    "    grad[i] = map_to_labels(g, labeling_noParcel, mask=mask, fill=np.nan)\n",
    "\n",
    "np.save(op.join(target_dir,f'sub-{sub}_gradients-aligned{specification}.npy'), grad) # save all together\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numrefields",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
