{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "Needed per subject:\n",
    "\n",
    "- *hardi_2mm_2b_as.rec & hardi_2mm_2b_ps.rec --> parec2nii (will give necessary bval/bves files and all 33 directions in one files)\n",
    "- *hardi_2mm_2b_as_bvalue1_diffori33.nii & *hardi_2mm_2b_ps_bvalue1_diffori33.nii as b0 images necessary for topup (fieldmap correction)\n",
    "- acqparams.txt = describing the phase encoding direction and echo time for TOPUP | checked the scan sequence, should be (according to ChatGPT given the info of the file) \n",
    "0  1  0  0.0215\n",
    "0 -1  0  0.0215\n",
    "\n",
    "- \n",
    "\n",
    "1. fslmerge -t b0_all sn_*_as_bvalue1_diffori33.nii sn_*_ps_bvalue1_diffori33.nii\n",
    "2. topup --imain=b0_all --datain=acqparams.txt --config=b02b0.cnf --subsamp=1 --out=topup_results --iout=corrected_b0\n",
    "3. bet corrected_b0.nii.gz brain -m -f 0.2 (ChatGPT, contradicts itself, better with b0 or T1 ?! -- ives error in next steps with T1 cause of mismatch in voxel numbers...), therefore: bet corrected_b0 nodif_brain -m\n",
    "4. fslmerge -t dwi_all.nii.gz  *hardi_2mm_2b_as.nii *hardi_2mm_2b_ps.nii\n",
    "5. paste -d' ' dwi_as.bval dwi_ps.bval > dwi_all.bval\n",
    "6. paste -d' ' dwi_as.bvec dwi_ps.bvec > dwi_all.bvec\n",
    "\n",
    "### A. \n",
    "7. Eddy:\n",
    "eddy --imain=dwi_all --mask=nodif_brain_mask \\                                              \n",
    "    --acqp=acqparams.txt --index=index.txt \\\n",
    "    --bvecs=dwi_all.bvecs --bvals=dwi_all.bval \\\n",
    "    --topup=topup_results --out=eddy_corrected\n",
    "8. dtifit: \n",
    "dtifit --data=eddy_corrected \\                                                              \n",
    "       --mask=nodif_brain_mask \\\n",
    "       --bvecs=eddy_corrected.eddy_rotated_bvecs \\\n",
    "       --bvals=dwi_all.bval \\\n",
    "       --out=dtifit_results\n",
    "#### B. without Eddy:\n",
    "7. applytopup --imain=dwi_all --topup=topup_results --datain=acqparams.txt --inindex=1 --method=jac --out=dwi_topup_corrected\n",
    "8. dtifit --data=dwi_topup_corrected --mask=nodif_brain_mask --bvecs=dwi_all.bvecs --bvals=dwi_all.bval --out=dtifit_topup_corrected_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://fsl.fmrib.ox.ac.uk/fslcourse/2019_Beijing/lectures/FDT/fdt1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Succesfull FA image generation:\n",
    "\n",
    "1.\tTransform the .par files to nifti while also creating the necessary .bval & .bvec files (parrec2nii --bvs *_ps.par)\n",
    "2.\tMerge all into on large 4D file (66 in dim4):  fslmerge -t dwi_all.nii.gz *_as.nii *_ps.nii\n",
    "    a.\tAlso merge bvec &bval files: paste -d' ' dwi_as.bval dwi_ps.bval > dwi_all.bval (same for .bvecs)\n",
    "3.\tMerge b0 files: fslmerge -t b0_all sn_*_as_bvalue1_diffori33.nii sn_*_ps_bvalue1_diffori33.nii\n",
    "4.\tGet distortion corrections: topup --imain=b0_all --datain=acqparams.txt --config=b02b0.cnf --subsamp=1 --out=topup_results --iout=corrected_b0\n",
    "5.\tApply topup results: applytopup --imain=dwi_all --topup=topup_results --datain=acqparams.txt --inindex=1 --method=jac --out=dwi_topup_corrected\n",
    "6.\tGet brain mask from mean dti image (the version where I generate the brain mask from corrected_b0 seems to misalign) :\n",
    "    a.\tfslmaths dwi_topup_corrected.nii.gz -Tmean dwi_topup_corrected_mean\n",
    "    b.\tbet dwi_topup_corrected_mean.nii.gz mask_dwi_topup_corrected_mean -m -f 0.2\n",
    "7.\tFit diffusion tensor model at each voxel: dtifit --data=dwi_topup_corrected --mask=mask_dwi_topup_corrected_mean_mask --bvecs=dwi_all.bvecs --bvals=dwi_all.bvals --out=dtifit _meanmask_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/usr/local/fsl/bin/dtifit --data=/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-02/dwi_all.nii.gz --out=/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-02/dtifit_results_GUI --mask=/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-02/nodif_brain_mask.nii.gz --bvecs=/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-01/bvecs_all_T.txt --bvals=/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-01/bvals_all_T.txt --wls\n",
    "\n",
    "\n",
    "what worked: \n",
    "dtifit --data=dwi_topup_corrected --mask=mask_dwi_topup_corrected_mean --bvecs=dwi_all.bvecs --bvals=dwi_all.bval --out=dtifit_meammask_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tract-Based Spatial Statistics (TBSS)\n",
    "https://andysbrainbook.readthedocs.io/en/stable/TBSS/TBSS_Overview.html\n",
    "\n",
    "--> wants all individual \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranpose files | not needed !\n",
    "\n",
    "fn_in = '/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-01/bvals_all.txt'\n",
    "fn_out = '/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-01/bvals_all_T.txt'\n",
    "# Read the file\n",
    "with open(fn_in, \"r\") as file:\n",
    "    lines = [line.strip().split() for line in file]\n",
    "\n",
    "# Transpose the data\n",
    "transposed = list(zip(*lines))\n",
    "\n",
    "# Write the transposed data to a new file\n",
    "with open(fn_out, \"w\") as file:\n",
    "    for row in transposed:\n",
    "        file.write(\" \".join(row) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numrefields",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
