{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename and Orga files to apply preprocess pipeline\n",
    "\n",
    "Needed per subject:\n",
    "\n",
    "- *hardi_2mm_2b_as.rec & hardi_2mm_2b_ps.rec --> parec2nii (will give necessary bval/bves files and all 33 directions in one files)\n",
    "- *hardi_2mm_2b_as_bvalue1_diffori33.nii & *hardi_2mm_2b_ps_bvalue1_diffori33.nii as b0 images necessary for topup (fieldmap correction)\n",
    "- acqparams.txt = describing the phase encoding direction and echo time for TOPUP | checked the scan sequence, should be (according to ChatGPT given the info of the file) \n",
    "0  1  0  0.0215\n",
    "0 -1  0  0.0215\n",
    "\n",
    "### Infos:\n",
    "https://fsl.fmrib.ox.ac.uk/fslcourse/2019_Beijing/lectures/FDT/fdt1.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Succesfull FA image generation:\n",
    "\n",
    "1.\tTransform the .par files to nifti while also creating the necessary .bval & .bvec files (parrec2nii --bvs *_ps.par)\n",
    "2.\tMerge all into on large 4D file (66 in dim4):  fslmerge -t dwi_all.nii.gz *_as.nii *_ps.nii\n",
    "    a.\tAlso merge bvec &bval files: paste -d' ' dwi_as.bval dwi_ps.bval > dwi_all.bval (same for .bvecs)\n",
    "3.\tMerge b0 files: fslmerge -t b0_all sn_*_as_bvalue1_diffori33.nii sn_*_ps_bvalue1_diffori33.nii\n",
    "4.\tGet distortion corrections: topup --imain=b0_all --datain=acqparams.txt --config=b02b0.cnf --subsamp=1 --out=topup_results --iout=corrected_b0\n",
    "5.\tApply topup results: applytopup --imain=dwi_all --topup=topup_results --datain=acqparams.txt --inindex=1 --method=jac --out=dwi_topup_corrected\n",
    "6.\tGet brain mask from mean dti image (the version where I generate the brain mask from corrected_b0 seems to misalign) :\n",
    "    a.\tfslmaths dwi_topup_corrected.nii.gz -Tmean dwi_topup_corrected_mean\n",
    "    b.\tbet dwi_topup_corrected_mean.nii.gz mask_dwi_topup_corrected_mean -m -f 0.2\n",
    "7.\tFit diffusion tensor model at each voxel: dtifit --data=dwi_topup_corrected --mask=mask_dwi_topup_corrected_mean_mask --bvecs=dwi_all.bvecs --bvals=dwi_all.bvals --out=dtifit _meanmask_results\n",
    "\n",
    "\n",
    "--> meeting with Zoltan & Tim\n",
    "* run topup directly on all DTI ims?! empirical question, look into FSL forum on latest opinions on this\n",
    "* play with BET params, visually check (every sub!?)\n",
    "\n",
    "### 2ndl Level\n",
    "* Zoltan does not like TBSS, rather apply some warp function, bring to standard space, test ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTI images in BIDS format:\n",
    "\n",
    "https://bids.neuroimaging.io/getting_started/folders_and_files/files.html#mri\n",
    "\n",
    "\n",
    "sub-<label>/\n",
    "    [ses-<label>/]\n",
    "        dwi/\n",
    "            sub-<label>[_ses-<label>][_acq-<label>][_rec-<label>][_dir-<label>][_run-<index>][_part-<mag|phase|real|imag>][_chunk-<index>]_dwi.bval\n",
    "            sub-<label>[_ses-<label>][_acq-<label>][_rec-<label>][_dir-<label>][_run-<index>][_part-<mag|phase|real|imag>][_chunk-<index>]_dwi.bvec\n",
    "            sub-<label>[_ses-<label>][_acq-<label>][_rec-<label>][_dir-<label>][_run-<index>][_part-<mag|phase|real|imag>][_chunk-<index>]_dwi.json\n",
    "            sub-<label>[_ses-<label>][_acq-<label>][_rec-<label>][_dir-<label>][_run-<index>][_part-<mag|phase|real|imag>][_chunk-<index>]_dwi.nii[.gz]\n",
    "\n",
    "parrec2nii --bvs *_ps.par\n",
    "\n",
    "* Filename entities or directories between square brackets (for example, [_ses-<label>]) are OPTIONAL.\n",
    "\n",
    "--> relevant: `dir` - Phase-Encoding Direction : The dir-<label> entity can be set to an arbitrary (!!) legitimate label (for example, dir-LR or dir-AP) to distinguish different phase-encoding directions. -- Therefore, if the dir-<label> entity is present in a filename, \"PhaseEncodingDirection\" MUST be defined in the associated metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prep files\n",
    "\n",
    "run the following for all subs\n",
    "\n",
    "for sub in $(seq -w 1 66); do mkdir /Volumes/mrenkeED/data/ds-dnumrisk/sub-${sub}/ses-1/dwi ; done\n",
    "\n",
    "for dir in as ps; do\n",
    "  for sub in $(seq -w 1 66); do\n",
    "    parrec2nii \\\n",
    "      /Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/mri/SNS_MRI_DNUMR_S000${sub}_01/*_${dir}.par \\\n",
    "      -o /Volumes/mrenkeED/data/ds-dnumrisk/sub-${sub}/ses-1/dwi \\\n",
    "      --bvs\n",
    "  done\n",
    "done\n",
    "\n",
    "{$(seq -w 1 66) adds the 0 for 1-9!}\n",
    "\n",
    "- Problems: sub-39; sub-64 (weird names, no ps/as specification --> assume that ps was done first (smaller acq number!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from sourcedata into sub-00/ses-1/anat and rename \n",
    "\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import shutil\n",
    "\n",
    "bids_folder = '/Volumes/mrenkeED/data/ds-dnumrisk'\n",
    "\n",
    "for sub in range(1,67):\n",
    "    sub = str(sub).zfill(2)\n",
    "    pati = op.join(bids_folder,f'sub-{sub}','ses-1','dwi')\n",
    "    files = os.listdir(pati)\n",
    "\n",
    "    for file in files:\n",
    "        ending = file.split('_')[-1] \n",
    "        dir = ending.split('.')[0] # take the last part of the filename (containing dir & filetye)\n",
    "        f_type = ending.split('.')[1] # take the last part of the filename (containing dir & filetye)\n",
    "        new_fn =  f'sub-{sub}_dir-{dir}_dwi.{f_type}'\n",
    "        print(new_fn)\n",
    "\n",
    "        os.rename(op.join(pati,file), op.join(pati,new_fn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge all into on large 4D file (66 in dim4): \n",
    "\n",
    "for sub in $(seq -w 1 66); \n",
    "\n",
    "do mkdir /Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/sub-${sub}\n",
    "\n",
    "do fslmerge -t  /Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/sub-${sub}/sub-${sub}_dir-all_dwi.nii /Volumes/mrenkeED/data/ds-dnumrisk/sub-${sub}/ses-1/dwi/sub-${sub}_dir-as_dwi.nii /Volumes/mrenkeED/data/ds-dnumrisk/sub-${sub}/ses-1/dwi/sub-${sub}_dir-ps_dwi.nii;  \n",
    "\n",
    "done\n",
    "\n",
    "for spec in bvals bvecs; do\n",
    "  for sub in $(seq -w 1 66); do\n",
    "    paste -d' ' \\\n",
    "    /Volumes/mrenkeED/data/ds-dnumrisk/sub-${sub}/ses-1/dwi/sub-${sub}_dir-as_dwi.${spec} \\\n",
    "    /Volumes/mrenkeED/data/ds-dnumrisk/sub-${sub}/ses-1/dwi/sub-${sub}_dir-ps_dwi.${spec} \\\n",
    "    > \\\n",
    "    /Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/sub-${sub}/sub-${sub}_dir-all_dwi.${spec}\n",
    "  done\n",
    "done\n",
    "\n",
    "--> this part is probably unnecessary, as I need these files only once cause they are the same for all subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tMerge b0 files: \n",
    "fslmerge -t b0_all sn_*_as_bvalue1_diffori33.nii sn_*_ps_bvalue1_diffori33.nii\n",
    "\n",
    "fslmerge -t /Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/sub-${sub}/sub-${sub}_dir-all-b0_dwi \\\n",
    "/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/mri/SNS_MRI_DNUMR_S000${sub}_01/*_as_bvalue1_diffori33.nii \\\n",
    "/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/mri/SNS_MRI_DNUMR_S000${sub}_01/*_ps_bvalue1_diffori33.nii\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\tGet distortion corrections:\n",
    "--> run on sciencecloud, takes long!\n",
    "\n",
    "[topup --imain=b0_all --datain=acqparams.txt --config=b02b0.cnf --subsamp=1 --out=topup_results --iout=corrected_b0]\n",
    "\n",
    "base_folder=/mnt_AdaBD_largefiles/Data/SMILE_DATA/DNumRisk/ds-dnumrisk/derivatives/dwi_preproc\n",
    "\n",
    "topup --imain=${base_folder}/sub-${sub}/sub-${sub}_dir-all-b0_dwi.nii.gz \\\n",
    "--datain=${base_folder}/acqparams.txt --config=b02b0.cnf --subsamp=1 \\\n",
    "--out=${base_folder}/sub-${sub}/topup_res \\\n",
    "--iout=${base_folder}/sub-${sub}/sub-${sub}_corrected_b0\n",
    "\n",
    "--> tried to apply it to all DWI-ims (directly) sub-01_dir-all_dwi.nii.gz), but does not work...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### locally --> tried to apply it to all DWI-ims (directly) sub-01_dir-all_dwi.nii.gz), but does not work...\n",
    "[adding `-b0`to imain makes it work again]\n",
    "\n",
    "topup --imain=/Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/sub-01/sub-01_dir-all_dwi.nii.gz \\\n",
    "--datain=/Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/acqparams.txt \\\n",
    "--config=b02b0.cnf --subsamp=1 \\\n",
    "--out=/Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/sub-01/topup_res \\\n",
    "--iout=/Volumes/mrenkeED/data/ds-dnumrisk/derivatives/dwi_preproc/sub-01/corrected_b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\tApply topup results: \n",
    "\n",
    "applytopup --imain=dwi_all --topup=topup_results --datain=acqparams.txt --inindex=1 --method=jac --out=dwi_topup_corrected\n",
    "\n",
    "applytopup --imain=${base_folder}/sub-${sub}/sub-${sub}_dir-all_dwi.nii.gz \\\n",
    "--topup=${base_folder}/sub-${sub}/topup_res \\\n",
    "--datain=${base_folder}/acqparams.txt --inindex=1 --method=jac \\\n",
    "--out=${base_folder}/sub-${sub}/sub-${sub}_dir-all_topup-corr_dwi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\tGet brain mask \n",
    "\n",
    "from mean dti image (the version where I generate the brain mask from corrected_b0 seems to misalign) :\n",
    "    a.\tfslmaths dwi_topup_corrected.nii.gz -Tmean dwi_topup_corrected_mean\n",
    "    b.\tbet dwi_topup_corrected_mean.nii.gz mask_dwi_topup_corrected_mean -m -f 0.2\n",
    "\n",
    "--> zoltan said I should check, each, play around with the params\n",
    "--> -f 0.4 seemed best for sub-01 so far...\n",
    "\n",
    "1. fslmaths ${base_folder}/sub-${sub}/sub-${sub}_dir-all_topup-corr_dwi -Tmean ${base_folder}/sub-${sub}/sub-${sub}_dir-all_topup-corr_mean_dwi\n",
    "2. bet ${base_folder}/sub-${sub}/sub-${sub}_dir-all_topup-corr_mean_dwi ${base_folder}/sub-${sub}/mask-f04_sub-${sub}_dir-all_topup-corr_mean_dwi  -m -f 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.\tFit diffusion tensor model at each voxel:\n",
    "\n",
    "dtifit --data=dwi_topup_corrected --mask=mask_dwi_topup_corrected_mean_mask --bvecs=dwi_all.bvecs --bvals=dwi_all.bvals --out=dtifit_meanmask_results\n",
    "\n",
    "dtifit --data=${base_folder}/sub-${sub}/sub-${sub}_dir-all_topup-corr_dwi \\\n",
    "--mask=${base_folder}/sub-${sub}/mask-f04_sub-${sub}_dir-all_topup-corr_mean_dwi_mask \\\n",
    "--bvecs=${base_folder}/sub-${sub}/sub-${sub}_dir-all_dwi.bvecs \\\n",
    "--bvals=${base_folder}/sub-${sub}/sub-${sub}_dir-all_dwi.bvals \\\n",
    "--out=${base_folder}/sub-${sub}/sub-${sub}_dtifit_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment & group level Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. align each subject's FA map to a standard template (like MNI152)\n",
    "\n",
    "1. coregister the DWI to the T1 - `flirt` or `epi_reg` \n",
    "2. Use `fsl_anat` or `fnirt` on the structural (T1-weighted) images, then apply the warp to the FA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fsl_anat -i sub-01_ses-1_T1w.nii [performs also fnirt?!]\n",
    "\n",
    "flirt -in fa.nii.gz \\\n",
    "      -ref T1.nii.gz \\\n",
    "      -omat fa2t1.mat \\\n",
    "      -out fa_in_T1.nii.gz \\\n",
    "      -cost bbr \\\n",
    "      -wmseg <white_matter_mask_from_fsl_anat> \\\n",
    "      -dof 6 \\\n",
    "      -init identity.mat \\\n",
    "      -schedule ${FSLDIR}/etc/flirtsch/bbr.sch\n",
    "\n",
    "T1_fast_pve_2.nii.gz\n",
    "\n",
    "\n",
    "applywarp -i fa_in_T1.nii.gz \\\n",
    "          -r <MNI152_T1_1mm.nii.gz> \\\n",
    "          -w T1_to_MNI_warp.nii.gz \\\n",
    "          -o fa_in_MNI.nii.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what did not work so far...\n",
    "epi_reg --epi=sub-01_dtifit_res_FA.nii.gz --t1=sub-01_ses-1_T1w.nii --t1brain=sub-01_ses-1_T1w_masked-brain.nii.gz --out=epi_reg_res --wmseg=T1_fast_pve_1.nii.gz\n",
    "\n",
    " ‚ùØ flirt -in sub-01_dtifit_res_FA.nii.gz -ref T1_biascorr.nii.gz -applyxfm -init fa2t1_epi_reg.mat -out fa_in_T1.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flirt -in sub-01_dtifit_res_FA \\\n",
    "    -ref anatT1/sub-01_ses-1_T1w.nii \\\n",
    "    -omat fa2t1.mat \\\n",
    "    -out fa_in_T1.nii.gz \\\n",
    "    -cost bbr \\\n",
    "    -wmseg anatT1/sub-01_ses-1_T1w.anat/T1_fast_pve_2.nii.gz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    -schedule ${FSLDIR}/etc/flirtsch/bbr.sch\n",
    "    -dof 6 \\\n",
    "    -init identity.mat \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranpose files | not needed !\n",
    "\n",
    "fn_in = '/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-01/bvals_all.txt'\n",
    "fn_out = '/Volumes/mrenkeED/data/ds-dnumrisk/sourcedata/tryout_DTI/sub-01/bvals_all_T.txt'\n",
    "# Read the file\n",
    "with open(fn_in, \"r\") as file:\n",
    "    lines = [line.strip().split() for line in file]\n",
    "\n",
    "# Transpose the data\n",
    "transposed = list(zip(*lines))\n",
    "\n",
    "# Write the transposed data to a new file\n",
    "with open(fn_out, \"w\") as file:\n",
    "    for row in transposed:\n",
    "        file.write(\" \".join(row) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numrefields",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
